{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shakespare.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of text:  5447744\n"
     ]
    }
   ],
   "source": [
    "print(\"len of text: \", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1609\n",
      "\n",
      "THE SONNETS\n",
      "\n",
      "by William Shakespeare\n",
      "\n",
      "\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bud buriest thy content,\n",
      "  And tender churl mak'st waste in niggarding:\n",
      "    Pity the world, or else this glutton be,\n",
      "    To eat the world's due, by the grave and thee.\n",
      "\n",
      "\n",
      "                     2\n",
      "  When forty winters shall besiege thy brow,\n",
      "  And dig deep trenches in thy beauty's field,\n",
      "  Thy youth's proud livery so gazed on now,\n",
      "  Will be a tattered weed of small worth held:  \n",
      "  Then being asked, where all thy beauty lies,\n",
      "  Where all the treasure of thy lusty days;\n",
      "  To say within thine own deep sunken \n"
     ]
    }
   ],
   "source": [
    "print(text[:1050])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars:  \n",
      " !\"&'(),-.0123456789:;<>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_`abcdefghijklmnopqrstuvwxyz|}\n",
      "vocab_size:  84\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(\"chars: \", ''.join(chars))\n",
    "print(\"vocab_size: \", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_i = { char:i for i,char in enumerate(chars)}\n",
    "undo_i = {i:char for i,char in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [do_i[c] for c in s]\n",
    "decode = lambda l: ''.join([undo_i[ix] for ix in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 60, 80, 8, 1, 34, 75, 1, 64, 74, 1, 45, 64, 68, 64]\n",
      "Hey, It is Timi\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Hey, It is Timi\"))\n",
    "print(decode(encode(\"Hey, It is Timi\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5447744]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "all_data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(all_data.shape, all_data.dtype) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 12, 17, 11, 20,  0,  0, 45, 33, 30,  1, 44, 40, 39, 39, 30, 45, 44,\n",
      "         0,  0, 57, 80,  1, 48, 64, 67, 67, 64, 56, 68,  1, 44, 63, 56, 66, 60,\n",
      "        74, 71, 60, 56, 73, 60,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 12,  0,  1,  1, 31,\n",
      "        73, 70, 68,  1, 61, 56, 64, 73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76,\n",
      "        73, 60, 74,  1, 78, 60,  1, 59, 60, 74])\n"
     ]
    }
   ],
   "source": [
    "print(all_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(all_data))\n",
    "train_data = all_data[:n]\n",
    "test_data = all_data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 12, 17, 11, 20,  0,  0, 45, 33])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([0]), output is 12\n",
      "when input is tensor([ 0, 12]), output is 17\n",
      "when input is tensor([ 0, 12, 17]), output is 11\n",
      "when input is tensor([ 0, 12, 17, 11]), output is 20\n",
      "when input is tensor([ 0, 12, 17, 11, 20]), output is 0\n",
      "when input is tensor([ 0, 12, 17, 11, 20,  0]), output is 0\n",
      "when input is tensor([ 0, 12, 17, 11, 20,  0,  0]), output is 45\n",
      "when input is tensor([ 0, 12, 17, 11, 20,  0,  0, 45]), output is 33\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "\n",
    "    print(f\"when input is {context}, output is {target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2574686, 3759761, 1188637, 4492827])\n",
      "inputs torch.Size([4, 8]) tensor([[75, 74,  1, 59, 70, 78, 69, 10],\n",
      "        [69, 10,  0,  0,  1,  1,  1,  1],\n",
      "        [68, 71, 67, 70, 80, 68, 60, 69],\n",
      "        [ 1, 28, 40, 41, 34, 30, 44,  1]])\n",
      "outputs torch.Size([4, 8]) tensor([[74,  1, 59, 70, 78, 69, 10,  0],\n",
      "        [10,  0,  0,  1,  1,  1,  1,  1],\n",
      "        [71, 67, 70, 80, 68, 60, 69, 75],\n",
      "        [28, 40, 41, 34, 30, 44,  1,  6]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(-1)\n",
    "\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(\"inputs\",xb.shape,xb)\n",
    "print(\"outputs\",yb.shape,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is [75], the target is 74\n",
      "when input is [75, 74], the target is 1\n",
      "when input is [75, 74, 1], the target is 59\n",
      "when input is [75, 74, 1, 59], the target is 70\n",
      "when input is [75, 74, 1, 59, 70], the target is 78\n",
      "when input is [75, 74, 1, 59, 70, 78], the target is 69\n",
      "when input is [75, 74, 1, 59, 70, 78, 69], the target is 10\n",
      "when input is [75, 74, 1, 59, 70, 78, 69, 10], the target is 0\n",
      "when input is [69], the target is 10\n",
      "when input is [69, 10], the target is 0\n",
      "when input is [69, 10, 0], the target is 0\n",
      "when input is [69, 10, 0, 0], the target is 1\n",
      "when input is [69, 10, 0, 0, 1], the target is 1\n",
      "when input is [69, 10, 0, 0, 1, 1], the target is 1\n",
      "when input is [69, 10, 0, 0, 1, 1, 1], the target is 1\n",
      "when input is [69, 10, 0, 0, 1, 1, 1, 1], the target is 1\n",
      "when input is [68], the target is 71\n",
      "when input is [68, 71], the target is 67\n",
      "when input is [68, 71, 67], the target is 70\n",
      "when input is [68, 71, 67, 70], the target is 80\n",
      "when input is [68, 71, 67, 70, 80], the target is 68\n",
      "when input is [68, 71, 67, 70, 80, 68], the target is 60\n",
      "when input is [68, 71, 67, 70, 80, 68, 60], the target is 69\n",
      "when input is [68, 71, 67, 70, 80, 68, 60, 69], the target is 75\n",
      "when input is [1], the target is 28\n",
      "when input is [1, 28], the target is 40\n",
      "when input is [1, 28, 40], the target is 41\n",
      "when input is [1, 28, 40, 41], the target is 34\n",
      "when input is [1, 28, 40, 41, 34], the target is 30\n",
      "when input is [1, 28, 40, 41, 34, 30], the target is 44\n",
      "when input is [1, 28, 40, 41, 34, 30, 44], the target is 1\n",
      "when input is [1, 28, 40, 41, 34, 30, 44, 1], the target is 6\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b, t]\n",
    "\n",
    "        print(f\"when input is {context.tolist()}, the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 84])\n",
      "tensor(4.9646, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(-1)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "        logits = self.token_embedding_table(idx) # B T C\n",
    "\n",
    "\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T,C)\n",
    "        targets = targets.view(B*T)\n",
    "        \n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx)\n",
    "\n",
    "            logits = logits[:, -1, :]\n",
    "            probs =  F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B,1)\n",
    "            idx = torch.cat((idx, idx_next), dim =1)\n",
    "        return idx\n",
    "\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
