Phenotyping Data and ML
The enormous volume, variety, velocity, and veracity of imaging and remote-sensing data
generated by such real-time platforms represent a ‘big data’ problem. The data generated
by these near real-time platforms must be efﬁciently archived and retrieved for analysis. Although
the analysis and interpretation of such (image-based) big data are challenging, the ensuing
possibilities that can impact on agricultural production make it a promising approach for HTP
and HTSP. ML approaches present a scalable, modular strategy for data analysis, especially for
the new application domain of ‘plant stress analytics’. Recent studies on HTSP using images
obtained from UAV-based platforms to detect weeds in wheat (Triticum aestivum L.) [23], maize
[21], and sunﬂower (Helianthus annuus L.) [24] using ML algorithms have paved a new path for
better stress management practices on spatial and temporal basis.
ML is an inherently multidisciplinary approach to data analysis that draws inspiration, and
borrows heavily, from probability theory, statistics, decision theory, visualization, and optimization. ML approaches are typically useful in situations where large amounts of data are
available, relating inputs (e.g., image data) to output quantities of interest (e.g., stress phenotypes). One of the major advantages of using ML approaches for plant breeders, pathologists,
physiologists, and biologists is the opportunity to search large datasets to discover patterns and
govern discovery by simultaneously looking at a combination of factors instead of analyzing each
feature (trait) individually. This was previously a major bottleneck because the high dimensionality
of individual images (coupled with the huge number of such images) makes them extremely
difﬁcult to analyze through classical techniques. Another key challenge is that the underlying
Figure 1. (A) High-throughput stress phenotyping in soybean ﬁeld at various growth stages and at different heights using
aircraft, UAV, and UGV. (B) Identiﬁcation, classiﬁcation, quantiﬁcation, and prediction (ICQP) of plant diseases in soybean.
(C) ML algorithms used in ICQP of plant stresses. (D) Classiﬁcation of ML algorithms into generative and discriminative.
Abbreviations: ANN, artiﬁcial neural network; BC, Bayes classiﬁer; BN, Bayesian network; BM, Boltzmann machine; CRF,
conditional random ﬁeld; CNN, convolutional neural network; DT, decision tree; DNN, deep neural network; GMM, Gaussian
mixture models; GP, Gaussian process; HMM, hidden Markov model; HC, hierarchical clustering, ICA, independent
component analysis; K-MC, K-means clustering; K-NN, k-nearest neighbor classiﬁer; Lat DA, latent Dirichlet allocation,
LDA, linear discriminant analysis; Lin R, linear regression; LR, logistic regression; MF, matrix factorization; NB, naïve Bayes;
NLR, nonlinear regression; PCA, principal component analysis; RF, random forests; SOM, self-organizing map; SVM,
support vector machine; UAV, unmanned aerial vehicle; UGV, unmanned ground vehicle.
processes for linking the inputs to the outputs are too complex to model mathematically. This is
particularly the case for plant stress phenotyping, where it is challenging to efﬁciently model the
holistic effect of genetic, agronomic, economic, meteorological, and human factor inputs on
stress and, ultimately, yield.
ML methods have been applied with spectacular results to similar problems [25] previously
presumed to be impossible to model. Examples include numerous success stories in various
domains ranging from computer vision (e.g., face recognition), speech processing (e.g., Google
voice, Apple's Siri) and natural language processing (e.g., IBM Watson), consumer predictive
analytics (e.g., Netﬂix movie recommender system) to bioinformatics (e.g., personalized genomics, drug design, and genome annotation) [26], cell biology [27], and disease tissue classiﬁcation in medicine [28,29]. The success of ML tools is attributed to their ability to identify a
hierarchy of features and generalized trends from available data. These tools have also proved
particularly adept at integrating disparate and often redundant data to draw coherent (and often
non-intuitive) patterns for identiﬁcation and quantiﬁcation. Finally, current progress in ML has
resulted in scalable, robust, and ﬂexible software tools (R packages, Matlab toolboxes, and
software packages such as Theano, Caffe for archetypal ML algorithms) [30–33] that make the
application of ML to disparate disciplines straightforward. The advances have percolated into
agricultural research, where there has been an increasing research effort to apply ML
approaches in diverse species, such as horticultural crops and forest tree species. This has
been driven in part by the increased investment by commercial companies and the decreasing
cost of imaging/sensor platforms.

ML-Enabled HTSP
In light of these developments, it is clear that ML-enabled HTSP will beneﬁt plant breeders,
physiologists, entomologists, pathologists, extension workers, and farmers by allowing screening of different stresses in an accurate, precise, and speedy manner (Table 1). This will also
directly enable the acceleration of the gene discovery process as well as the introduction of novel
selection protocols for complex quantitative traits such as biotic and abiotic stresses and yield.
ML-enabled HTSP will also enhance our understanding of pathogen–plant interactions [34] as
well as the interaction of plants with other stresses.

What is ML?
ML refers to a group of computerized modeling approaches that can learn patterns from the data
so as to make automatic decisions without programming explicit rules. The main idea of ML is to
effectively utilize experiences or example scenarios to discover underlying structures, similarities,
or dissimilarities present in data to explain or classify a new experience or an example scenario
properly. A key ability of ML tools is their ability to generalize trends and/or patterns from available
data.
There are a large number of choices of ML tools. It is important for an application expert to make
a judicious choice on a speciﬁc ML method to deploy for his/her speciﬁc problem. We advocate
that the practitioner should (carefully) down-select from the plethora of ML choices based on the
type and amount of available data and problem formulation. In the context of plant stress
phenotyping, we identify four distinct classes of problem formulation: (i) identiﬁcation/detection,
(ii) classiﬁcation, (iii) quantiﬁcation/estimation, and (v) prediction (Figure 1B,C). Furthermore,
preprocessing steps such as dimension reduction, clustering, and segmentation can also be
crucial for successful decision-making.

Structure of a ML Process
Typically, a large fraction of the dataset, known as the ‘training dataset’, that represents the
entire population is used for calibrating the model. The remaining dataset is used to test the

calibrated model, and is termed the ‘testing dataset’. The next step after training is to validate the
learnt model on a new set of data (from different or same population). Once the accuracy and
precision of the model is high enough, it can be used on a routine basis to identify, classify,
quantify and predict particular stress features.
We discuss this process in greater detail next, particularly focusing on clarifying the choice of ML
tools to use based on two different points of view, namely the learning process (how are features
learnt) and the modeling objective (what is being learnt).

The Learning Process – Supervised versus Unsupervised

The ﬁrst point of view concerns whether or not the ML model is provided with the labels to the
data it uses for model training. Here, a label is a trait (such as diseased plant or type of crop plant)
that is associated with an image. For example, suppose the objective of a ML model is to
distinguish between maize, soybean [Glycine max (L.) Merr.], and sunﬂower plants after

collecting a large number of images. If the model is trained with a set of such images where each
is labeled as soybean, maize or sunﬂower, the learning process is termed ‘supervised’.
Alternatively, if the training images are provided without any label, the learning process is
‘unsupervised’. Note that although some ML tools can be trained either in a supervised or
an unsupervised manner, some can be trained in both ways. With the supervised learning
process, a model essentially tries to learn a map between the input dataset and the corresponding output labels. For the given example, it means that a model trained in a supervised
manner learns how to map all the soybean examples to the soybean label, and so on.
Support vector machines (SVM) and regular artiﬁcial neural networks (ANN) are among the
prominent examples of supervised schemes. By contrast, an unsupervised method does not
have speciﬁc output labels associated with input images. It identiﬁes structures or features
present in the images, such as the presence of tassels in maize, or the presence of trifoliate
leaves in soybean. In many cases, the features identiﬁed in the unsupervised process may not be
meaningful to a human user. Various clustering, mixture models, and dimension-reduction
techniques fall under this category. Often ML models can be developed by using partly labeled
data. This training scheme is known as ‘semi-supervised’ learning.

The Modeling Objective – Generative versus Discriminative
A second point of view for ML method categorization is the modeling objective: whether the
model being trained is to distinguish between two different data patterns or to be able to learn
and generate similar patterns synthetically. In the context of the previous example, a maize and
soybean plant can be distinguished based on the presence or absence of tassels or pods. A
model developed with only this difference would be termed a ‘discriminative model’. Naturally,
many supervised methods such as SVM and ANN fall under this category. However, such a
model does not learn other features of the objects. Thus, a discriminative model that distinguishes a soybean plant from a maize plant based on the presence of tassels fails to differentiate
between an image of a maize plant and that of sorghum [Sorghum bicolor (L.) Moench] plant.
Therefore, a discriminative model is typically built for a predetermined speciﬁc task. On the other
hand, a model that captures the overall data pattern such that it is able to generate synthetic
images is known as a ‘generative model’. It follows that a single generative model can be useful
for many decision tasks at the same time. Mixture models, hidden Markov models, and
Boltzmann machines are prominent examples of generative models.
Given a large volume of data, discriminative models usually perform better than generative
models, especially for classiﬁcation tasks, such as distinguishing images of soybean plants from
a maize plant. However, generative models can achieve slightly better performance compared to
discriminative ones with low training data volume. In addition, generative models tend to be more
robust to overﬁtting issues (i.e., a model learns training data too well and performs very poorly for
unseen test data).
Figure 1D schematically illustrates the categorization of several ML methods into classes of
generative versus discriminative, and supervised versus unsupervised. Although it seems that
supervised models are more likely to be discriminative in nature, and generative models should
not need output labels for training, there are examples of unsupervised discriminative models
and supervised generative models. For example, the widely popular K-means clustering technique usually follows an unsupervised training scheme. Even so, it is not possible to generate
new data examples reliably using only the cluster centers and groupings. Most of the unsupervised generative techniques can be learned in a supervised manner when the target class
information is incorporated as one of the data features. Apart from such variations (as shown in
Figure 1D), many of the ML tools have minor variations based on particular aspects such as
underlying model structure (e.g., linear vs nonlinear) and training algorithm.

The Role of Preprocessing in ML-HTSP
The crucial step for the successful deployment of ML methods is careful preprocessing of the
image data. There are multiple examples where a careful choice of preprocessing of the
collected image datasets has resulted in substantial improvements in ML performance. Preprocessing can vary from very simple operations including image cropping, contrast enhancement, and removal of background to signiﬁcantly more complex operations such as clustering
and dimensionality reduction using principal component analysis (PCA). However, the overarching principle of preprocessing the data is ‘concentration of information’. That is, the original
datasets may contain a large quantity of unnecessary or conﬂicting information that can result in
poor ML performance. By preprocessing, the signal-to-noise ratio (ratio of useful to useless
information) is improved. This directly enhances the ability of the ML model to easily recognize
useful patterns or trends and to separate the data into appropriate classes.
Preprocessing is the stage where domain knowledge is crucial. The domain expert identiﬁes
features in the image that are relevant or important for training the model. For example, the
removal of background (soil, dirt, and tags, etc.) from the foreground to identify the plant canopy
is generally a crucial step. Following this, a variety of image processing tools can be used to
convert these raw datasets into a more relevant dataset that contains the extracted features.
Examples of preprocessing operations include: (i) segmentation of images; (ii) contrast enhancement to detect edges; (iii) thresholding images into binary data; (iv) converting one image format
into other [RGB to greyscale; RGB to hue saturation value (HSV)]; (v) de-noising images using
ﬁlters [band-pass, low-pass, fast Fourier transform (FFT)]; (vi) extracting features at different
scales using image transforms (FFT, wavelet transforms, Haar transforms, Hough transforms,
Radon transforms); (vii) pixel-based classiﬁcation; (viii) clustering of images into classes; and (ix)
dimensionality reduction of images. Several of the ML tools discussed here can in fact be applied
to these preprocessing stages.
There are several examples of the utility of such preprocessing steps. For early site-speciﬁc weed
management (ESSWM) in wheat, a UAV-based platform was equipped with a visible-range
camera to capture ultra-high resolution images. Otsu's thresholding method was then used to
differentiate wheat crop plants from weeds [23]. In sunﬂower, a quadrocopter equipped with
RGB and multispectral sensors was used to detect weeds to optimize herbicide application. A
pixel-based classiﬁcation approach was used for weed identiﬁcation. Similarly, image segmentation [21,24,35] followed by automatic object-based image analysis (OBIA) was used in
sunﬂower and maize to identify spatial and spectrally consistent objects.

ML Approaches to ICQP
Identiﬁcation of Stress
Identiﬁcation methods involve detection of a speciﬁc stress amid other potential stresses in the
ﬁeld. Here, preprocessing of image data is crucial. This is especially important for applications
involving high-throughput imaging, where plant stressors (such as weeds, nutrient, disease, and
insects) must be automatically identiﬁed. In the past, ML methods such as SVM, neural networks
(NNs), kernel methods, and instance-based approaches have been used to detect various
stresses. The SVM method has been used successfully in a variety of scenarios for stress
identiﬁcation in plants.
SVM Methods
SVM methods have been applied to a variety of plants for disease and stress identiﬁcation. They
are deployed in the citrus industry to contain citrus greening (caused by phloem-limiting
bacteria), also known as Huanglongbing (HLB). Early identiﬁcation is crucial for effectively
controlling the spread of HLB. ML was used for the identiﬁcation and estimation of HLB based
on ﬂuorescence imaging spectroscopy data of leaf samples [36]. The images were

preprocessed (segmented) and the extracted features were used as an input to SVM. In another
example, two aerial imaging platforms were compared for the identiﬁcation of HLB diseases in an
infected citrus orchard. An aircraft sensing platform equipped to capture hyperspectral images
and a UAV platform equipped with a multiband imaging camera were used, and images
obtained from both platforms were segmented and piped to a SVM classiﬁer. Results showed
that a (non-linear) SVM with kernel worked better than (linear) SVM, LDA, and QDA [37]. Similarly,
in sugar beet (Beta vulgaris L.), early identiﬁcation of three diseases, Cercospora leaf spot, leaf
rust, and powdery mildew, was performed using SVM with a radial basis function as kernel [38].
The same idea was deployed in cotton to identify damage by green stink bug, bacterial angular
blight, and Ascochyta blight using a SVM classiﬁer [39], as well as in tomato (Solanum
lycopersicum L.) to identify viruses: tomato yellow leaf curl virus and tomato yellow leaf curl
disease [40].
SVM (combined with a Gaussian process classiﬁer) was used for the automatic identiﬁcation of
soil moisture stress using remote visible and thermal images in spinach canopies, where the
efﬁcacy of using a combination of methods was explored. In another study, visible and thermal
imaging were combined with depth information to automatically identify powdery mildew of
tomato plants at an early growth stage using a SVM classiﬁer kernel [31]. Variants of the SVM
method have also proven to be useful for identiﬁcation. In rice (Oryza sativa L.], the hierarchical
identiﬁcation of nutrient deﬁciency symptoms using scanned images was carried out using
support vector feature selection (SVFS). Hierarchical identiﬁcation was able to detect the NPK
(nitrogen, phosphorus, and potassium) stress effectively with enhanced identiﬁcation accuracy
[41].
Artiﬁcial Neural Nets (ANN) and Variants
Simple image processing, followed by ANN, was used for detecting and identifying three orchid
seedling diseases: bacterial soft rot, bacterial brown spot, and Phytopthora black rot [42].
Discriminant Analysis
Spectral reﬂectance data were recorded from healthy and HLB-infected citrus leaves, and
various classiﬁer methods (discriminative and supervised methods) were used to identify
infected leaves using quadratic discriminant analysis (QDA), linear discriminant analysis
(LDA), and k-nearest neighbor (k-NN) and soft independent modeling of class analogy (SIMCA)
[43]. In sugar beets, hyperspectral canopy reﬂectance was used to identify stress symptoms
instigated by beet cyst nematode and Rhizoctonia crown and root rot [44].
Gaussian Mixture Models
Preprocessing followed by the application of Gaussian mixture models has been used to identify
both biotic and abiotic stresses [45]. Canopy images were taken in a stressed wheat ﬁeld, at
differential levels of irrigation (abiotic stress) and inoculated with wheat streak mosaic virus (biotic
stress).
K-means Clustering and Variants
Water and nutrient stress at the crop canopy level have been studied using hyperspectral images
that were analyzed using simplex volume maximization (SiVM), an unsupervised clustering
approach. The SiVM algorithm was found to be adept at detecting drought stress using
hyperspectral images four days before the appearance of symptoms visible to the human
eye. The unsupervised nature of SiVM also provided useful new insights into the data [11,25].
Dimensionality Reduction and Clustering
The automatic extraction of hyperspectral signatures using the Bayes factor algorithm with
Dirichlet-aggregation regression (DAR) resulted in rapid, reliable, and data-driven approach for
phenotyping plants for both biotic and abiotic stresses [11]. In barley (Hordeum vulgare L.), the
DAR algorithm was used for the presymptomatic prediction of drought stress at an early stage
using hyperspectral images [46].
Self-Organizing Map (SOM) and Bayes Classiﬁer
Both supervised (Bayesian classiﬁer) and unsupervised (SOM) ML approaches were used for
segmenting diseased tomato plants. Diseased regions on the tomato canopy were identiﬁed
using the preprocessed tomato images by a SOM model [20].
Classiﬁcation of Stress
Classiﬁcation is an extension of identiﬁcation; however, instead of identifying a particular stress
amid different stresses, a classiﬁer is used to classify stress into labeled classes on the basis of
stress symptoms and signatures. Classiﬁcation methods often include a preprocessing step,
usually a segmentation step followed by the extraction of features that feed into some type of
classiﬁer. For instance, drought stress can be classiﬁed into: no stress, moderate stress, and
heavy stress. Examples from various crops are presented below illustrating the use of classiﬁcation algorithms in various stresses.
ANN
A combination of K-means clustering followed by ANN, using fused information from RGB and
multispectral camera imaging, was used to develop a 3D model of leaves to differentiate the two
sugar beet diseases, Cercospora beticola and Uromyces betae [47]. In another example,
thermal and hyperspectral imaging were analyzed to identify and classify symptoms caused
by three Alternaria species in the oilseed brassica. The majority of the available classiﬁers present
in Weka (useful data-mining software in java) were tested, and eight classiﬁers were used to
make comparisons. The back-propagation neural networks (BNNs) classiﬁcation model displayed the highest prediction accuracy for classifying Alternaria species [48].
SVM
A SVM-based method was used to classify healthy and unhealthy Arabidopsis plants on the basis
of symptoms instigated by colonization of the human pathogen Salmonella Typhimurium [49]. The
SVM model was comprehensively tested on 1200 individual Arabidopsis plants with positive
results [50]. In further work, classiﬁcation error was reduced using SVMs compared to other ML
methods such as decision trees and ANNs. The classiﬁcation accuracy of three sugar beet
diseases increased with increasing disease severity. This is especially true when hyperspectral
reﬂectance-based vegetation indices were used with SVM for the automatic classiﬁcation of
disease severity of three sugar beet diseases (Cercospora leaf spot, leaf rust, and powdery
mildew). Another example of the usefulness of SVM was the identiﬁcation and classiﬁcation of
stoneﬂy larvae from images. Haar random forest feature extraction, in combination with SVM
classiﬁer, was able to differentiate and classify stoneﬂy larvae from other insect species [51].
LDA, K-Means, and Coupled Methods
ML methods were used to classify the presence of aﬂatoxins, which are toxic compounds
produced by fungus Aspergillus ﬂavus and Aspergillus parasiticus [52]. Fluorescence (UV
illumination) and reﬂectance (halogen excitations) were used as input data in this case. Preprocessing was performed to extract features using Guyon's SVM-RFE, classical Fisher discriminant power, and PCA. These extracted features were used as inputs to classiﬁers such as
LDA (linear discriminant analysis) and MLP. Another paper classiﬁed the RGB images into
‘healthy’ and ‘injured’ classes of clover plants that were exposed to varying level of ozone.
Various pixel-classifying methods were compared such as LDA, K-means clustering, FPM-T2 (ﬁt
to a pattern multivariate image analysis combined with T2 statistics), and FPM-RSS (FPM
combined with residual sum of squares statistics) [53].

Box 1. Key Take-Away Points for Practitioners
Identiﬁcation
(i) A large variety of ML methods have been successfully applied to the disease identiﬁcation problem. This is an area
where preprocessing of images will be very useful.
(ii) There are two ways to frame a disease identiﬁcation problem for ML based on the amount of data available. (a) When
statistically signiﬁcant nominal (healthy) and diseased datasets are available, it is best to use supervised discriminative
models that are trained to distinguish between these classes. (b) In the absence of a statistically signiﬁcant amount of
data (or unbalanced data, see next point below), the best approach is to learn the nominal model of the un-diseased
plant (which is feasible due to the availability of data of the healthy plant) using unsupervised methods. Then simple
outlier detection can be deployed to identify off-nominal (or diseased) cases.
(iii) We strongly encourage practitioners to refrain from training disease identiﬁcation models using very small datasets. It
is especially important to be vigilant against unbalanced data for training where one state (usually, the healthy state) has
much more data instances than the other diseased states.
Classiﬁcation
(i) We encourage the practitioner to ensure the statistical signiﬁcance of the available dataset.
(ii) Preprocessing of data is crucial, as is using domain knowledge.
(iii) Current trends are to always use supervised methods, which are mostly discriminative.
(iv) Be vigilant against the overﬁtting problem. A best practice is to always ensure that regularization option is turned on
in any ML method.
(v) It is important to note that these methods can only distinguish between known/trained classes. They cannot be
deployed to identify unknown/untrained symptoms (so-called extrapolatory mode).
(vi) We encourage practitioners to extract and report detection conﬁdence out of the classiﬁer.
Quantiﬁcation
(i) There are very few reported applications of ML for stress quantiﬁcation, and this provides tremendous opportunities
for plant scientists and breeders. Most current work formulates the quantiﬁcation problem as a classiﬁcation problem
with ﬁner resolution.
(ii) Our recommendation is that unsupervised generative models can be very successful for quantiﬁcation. This can also
work with smaller datasets. The basic idea is to learn the nominal (healthy state) model. The severity of the diseased state
is quantiﬁed as the distance/offset from this nominal state.
(iii) We strongly recommend practitioners to explore the use of Bayesian networks, deep neural nets, and latent Dirichlet
allocation for this class of problems.
Prediction
(i) Most prediction applications of ML are limited to early detection of disease onset.
(ii) Current phenotyping approaches can be extended to obtain time-varying traits. Here, more sophisticated models
can be used with great utility. Examples include HMM methods, dynamic Bayesian networks, and recurrent neural
networks.

Quantiﬁcation of Stress
There are fewer reports describing the use of ML approaches to quantify stresses, and this
provides tremendous opportunities for plant scientists and breeders. Quantiﬁcation methods are
an extension of classiﬁcation methods where each class is quantiﬁed on the basis of stress
severity. In case of plant diseases, disease severity [54] can be used to quantify various diseases.
For example, rust severity in wheat can be quantiﬁed on a scale of 0–100% [55]. Quantiﬁcation
algorithms are usually best preceded by a preprocessing stage to separate foreground from
background, edge detection, and contrast enhancement. A good example of the beneﬁt of
preprocessing of images for quantiﬁcation is illustrated in [56] where color mapping (converting
from native RGB to other non-native formats such as HSV) followed by segmentation was used
to quantify disease severity of PHYVV (pepper huasteco yellow vein virus) on chili pepper
(Capsicum annuum L.) plants. Examples from various other crops are presented next.
SVM
Leaf miner pest causes major losses in vegetable and ornamental plants. SVM applied to nearinfrared spectral reﬂectance using spectrophotometer and digital leaf images of tomato plants of
damaged leaves was used to successfully quantify damage degree (DD) into ﬁve levels [57].
Automatic detection method was used to detect and quantify Verticillium wilt (VM) on a large
scale in olive using hyperspectral sensor and thermal camera mounted on aircraft. The spatial
distribution of VM was assessed at ﬁeld level and severity classes (0–4 rating scale quantiﬁed into
0–100% severity level) predicted by LDA and non-linear SVM methods. Both ML methods
showed good results in detecting and quantifying VM severity in olives (Olea europaea L.) [58].
Prediction of Stress
The prediction of plant stress at an early stage before it is visible to the human eye has substantial
implications for the timely and cost-effective control of stress. There are very few reported
activities on using ML for the prediction of stresses, making this the next big frontier for research
efforts. This has tremendous implications for prescription farming and precision agriculture.
SVM
In predicting rice blast disease, SVM was used for the development of a weather-based
prediction model [59]. The performance of the SVM-based approach was compared to the
ANN variants; back-propagation neural network (BPNN) and generalized regression neural
network (GRNN), and also to conventional multiple regression. The SVM-based approach
outpaced all the three methods in cross-location and cross-year models, indicating their role
in early forecasting of plant diseases. Other examples include the prediction of drought-induced
stress in barley using hyperspectral images using an SVM variant, ordinal classiﬁcation approach
[60]. In barley for the presymptomatic detection of water stress, DAR algorithm was used on
images obtained using hyperspectral camera. The DAR algorithm was efﬁcient in predicting
stress before symptoms were visible to human eye [46].

Strategies for the Development of Efﬁcient ML Applications in Plant
Breeding
ML methods can play an extensive role in breeding for stress tolerance and for rapid phenotyping. These approaches can be used in decision-making for parent selection to use in

Box 2. Precision Phenotyping Using ML Algorithms in Agriculture: Best Practices
Advances in technology have made HTSP feasible. Appropriate ML tools can be used for all four stages (stress
identiﬁcation, classiﬁcation, quantiﬁcation, and prediction). High-throughput image-based phenotyping of plant stressrelated traits to complement high-throughput sequencing will assist in ﬁnding new genes and quantitative trait loci (QTLs)
using linkage mapping and genome-wide association studies (GWAS) together with training genome-wide selection
models for various plant stress traits [74]. Speciﬁcally, the high-throughput phenotypic information on a particular stress
can be used in association with genotypic information by means of QTL [75,76], GWAS [77,78], or expression studies to
bridge the genotype–phenotype gap. Relating time-series phenotypic data with time-series gene expression may
provide novel insights into cellular mechanisms. Time-series image data [79,80] obtained in experiments using HTP
platforms such as UAVs and autonomous rovers (ground robots), integrated into a viable ML pipeline, will allow the study
of the time-dependent gene turn-on and turn-off mechanisms and provide insight into the molecular basis of disease
resistance. HTP can also be used for phenotyping different ﬁelds for the same stress to understand the spatiotemporal
difference in the expression of stress. The big advantage of ML algorithms is that plant scientists can use them proﬁciently
in stress identiﬁcation, classiﬁcation, quantiﬁcation, and prediction using tools packaged in the graphical user interface
(GUI) without knowing the underlying mathematical and computational complexities. We advocate the following best
practices for maximizing the effectiveness of ML tools:
ML for Practitioners
It is useful to identify which type of ML method is best suited by triaging the ML methods based on amount of data
available as well as the type of data (labeled vs unlabeled). Figure 1C,D will be beneﬁcial for this purpose.
Discriminative methods work better for labeled and large datasets, while generative methods work better for smaller
datasets (both labeled and unlabeled).
It may be worthwhile for practitioners to explore the use of generative unsupervised models as a means to identify latent
features from datasets. This is an area that is relatively unexplored, but holds great promise.
Preprocessing is where domain knowledge can be leveraged to improve the signal-to-noise ratio in the data.
For ML methods that are classiﬁed as discriminative and supervised, the use of preprocessing before deploying ML tools
is essential to substantially improve ML performance.
In cases where it is difﬁcult to translate domain knowledge into feature crafting, unsupervised preprocessing methods
should be explored. This may be particularly useful for high-dimensional data such as hyperspectral data.

hybridization schemes, and in generation advancement and selection. An example of an
application using ICQP is presented below.
Identiﬁcation
Use HTP platform [UAV, unmanned ground vehicle (UGV)] for taking images of breeding plots in
plant stress nurseries, and yield tests. Perform image processing and apply ML algorithms. ML
identiﬁes which stress is present in each breeding plot.
Classiﬁcation
Use ML approaches to classify stress in each breeding plot. For instance, determine if a
genotype is resistant or susceptible to a particular stress. This information can be directly used
in a breeding decision scheme to select stress resistance genotypes.
Quantiﬁcation
Use ML approaches to quantify the stress. For example, quantiﬁcation may be on a 0–100%
scale of expression, such as percent infection severity. Use the information generated by ML
approach through quantiﬁcation to make selections to identify stress-resistant genotypes for
further testing or commercialization.
Prediction
Use ML approaches on prior disease and weather data to make early stage prediction on the
expression of stresses for breeding and selection decisions.
In addition to plant stresses, advances have been made in analyzing other traits using ML to
predict yield [61–63], biomass [64,65], root traits [66,67], and adaptation traits [68].

Concluding Remarks and Outlook
ML tools provide a very powerful framework to assimilate data, and the utility of these tools is
especially important considering current progress in HTP approaches that easily generate
terabytes of data. Appropriate choice and usage of ML tools is crucial for obtaining the maximum
possible beneﬁts of these sophisticated approaches. This review provides a comprehensive
overview of ML alongside best practices of using these ML tools to enable stress phenotyping
(Boxes 1,2). Using advanced ML tools for plant stress phenotyping is a very new area, with the
plant community focusing on a small number of ML methods (such as SVM and ANN). As part of
this review, we have identiﬁed several future avenues for using ML techniques that show
tremendous promise but remain currently unutilized by the phenotyping community (see
Outstanding Questions). Furthermore, the concepts discussed here can be applied to data
collected across the spectrum of complexity and sophistication (from manually captured camera
imaging to automated high-throughput imaging systems), as well as scale (from individual plant
to plot to ﬁeld).
The outlook for ML tools in agriculture is very promising. A key ingredient for successful largescale application of ML is the seamless integration of data analytics within the data collection
and curation pipeline. Such a computational ecosystem (that links data collection, data
storage, and curation with ML-based data analytics) will open up tremendous opportunities
to accelerate breeding and to solve foundational problems in genomics and predictive phenomics. Promising examples of this vision include the Integrated Analysis Platform (IAP) [69]
and the i-Plant nitiativeii A crucial catalyst for such advances will be to foster multidisciplinary
research teams such that advances in engineering, plant sciences, and informatics can be
leveraged in a rational way. This review will enable such teams by providing a common language
of communication related to ML tools.